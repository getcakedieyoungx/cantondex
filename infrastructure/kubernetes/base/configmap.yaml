apiVersion: v1
kind: ConfigMap
metadata:
  name: cantondex-config
  namespace: cantondex
data:
  ENVIRONMENT: "production"
  LOG_LEVEL: "INFO"
  LOG_FORMAT: "json"

  # Database Configuration
  DATABASE_POOL_SIZE: "20"
  DATABASE_MAX_OVERFLOW: "10"

  # Redis Configuration
  REDIS_SSL: "true"

  # Kafka Configuration
  KAFKA_SASL_MECHANISM: "SCRAM-SHA-256"
  KAFKA_SECURITY_PROTOCOL: "SASL_SSL"

  # Service Configuration
  JWT_ALGORITHM: "RS256"
  JWT_EXPIRATION_HOURS: "24"

  # Rate Limiting
  ENABLE_RATE_LIMITING: "true"
  RATE_LIMIT_REQUESTS: "10000"
  RATE_LIMIT_PERIOD: "3600"

  # CORS Configuration
  ALLOW_CREDENTIALS: "true"

  # Monitoring
  PROMETHEUS_ENABLED: "true"
  JAEGER_ENABLED: "true"

  # Feature Flags
  ENABLE_AUDIT_LOGGING: "true"
  AUDIT_LOG_RETENTION_YEARS: "7"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-gateway-config
  namespace: cantondex
data:
  api-gateway.conf: |
    server {
      listen 8000;

      # Rate limiting
      limit_req_zone $binary_remote_addr zone=api:10m rate=100r/s;
      limit_req zone=api burst=200 nodelay;
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: matching-engine-config
  namespace: cantondex
data:
  matching-engine.toml: |
    [server]
    listen_addr = "0.0.0.0:50051"

    [database]
    pool_size = 20

    [logging]
    level = "info"
    format = "json"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: cantondex
data:
  kafka-topics.sh: |
    #!/bin/bash

    # Create topics
    kafka-topics --create --topic trades --partitions 10 --replication-factor 3 --if-not-exists
    kafka-topics --create --topic orders --partitions 10 --replication-factor 3 --if-not-exists
    kafka-topics --create --topic settlements --partitions 10 --replication-factor 3 --if-not-exists
    kafka-topics --create --topic alerts --partitions 5 --replication-factor 3 --if-not-exists
    kafka-topics --create --topic compliance-events --partitions 5 --replication-factor 3 --if-not-exists

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: cantondex-monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      - job_name: 'api-gateway'
        static_configs:
          - targets: ['api-gateway:8000']

      - job_name: 'matching-engine'
        static_configs:
          - targets: ['matching-engine:50051']

      - job_name: 'settlement-coordinator'
        static_configs:
          - targets: ['settlement-coordinator:8001']

      - job_name: 'risk-management'
        static_configs:
          - targets: ['risk-management:8002']

      - job_name: 'notification-service'
        static_configs:
          - targets: ['notification-service:8003']

      - job_name: 'compliance-service'
        static_configs:
          - targets: ['compliance-service:8004']

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: cantondex-logging
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/cantondex*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <match kubernetes.**>
      @type elasticsearch
      @id output_elasticsearch
      @log_level info
      include_tag_key true
      host elasticsearch.cantondex-logging.svc.cluster.local
      port 9200
      logstash_format true
      logstash_prefix cantondex
      logstash_dateformat %Y.%m.%d
      include_timestamp false
      type_name _doc
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_interval 5s
        retry_forever false
        retry_max_interval 30
        retry_timeout 72h
        chunk_limit_size 2M
        total_limit_size 512M
        overflow_action block
      </buffer>
    </match>
